{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usual stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# searching algorithm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# performance\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# NLP\n",
    "import preprocessor as p\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) load in the data and the model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user data with all features\n",
    "df = pd.read_csv(\"Final datasets/model_data/users_5G_with_features.csv\")\n",
    "# results of the bot detection model\n",
    "df2 = pd.read_csv(\"Final datasets/bot_tagged_data/bot_predict_5G.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11340, 90)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine for what we need\n",
    "df = df.iloc[:,1:]\n",
    "tagged = df2.iloc[:,[2,3]]\n",
    "df = df.merge(tagged,how='left',left_on='username',right_on='username')\n",
    "df.verified = df.verified*1\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11334, 90)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some usernames appear twice - we'll exclude\n",
    "df = df.drop_duplicates(subset=['username'])\n",
    "# for final output\n",
    "df_final = df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove bots and store their usernames\n",
    "bots = df[df['predicted_class'] == 'bot'].copy()\n",
    "bots = set(bots.username)\n",
    "len(bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11310, 89)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop bots from the working df\n",
    "df = df[df['predicted_class']!='bot'].copy()\n",
    "df = df.iloc[:,:-1]\n",
    "\n",
    "# for later as well\n",
    "df_orig = df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Filter out most credible business/org/ngo accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many accounts will be very clearly business/organisations/ngos and so we can remove them from the working df. The average twitter account has 707 followers, our average is ~9000 skewed by large accounts (Ny times etc) and so we will identify accounts with above average followings as *not* the accounts of real normal people.\n",
    "\n",
    "Large followings may also influence the content posted and so for authentic thoughts we aren't looking at accounts with large audiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 6655.702298850575\n",
      "Updated average: 776.084377372817\n",
      "(10536, 89)\n"
     ]
    }
   ],
   "source": [
    "# drop accounts with higher than average followers - 9000 or so and skewed by big accounts\n",
    "average_followers = df.followers.mean()\n",
    "print(\"Average:\", average_followers)\n",
    "df = df[df['followers'] <= average_followers].copy()\n",
    "\n",
    "print(\"Updated average:\",df.followers.mean())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA has revealed some common terms used in the bios of accounts related to the climate emergency domain. We also want to target collective pronouns so 'we' is included as an indicator of a personal twitter account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove accounts with domain specific pronouns/terms in bios\n",
    "df['description'] = df['description'].str.casefold()\n",
    "bios = []\n",
    "terms = ['we','ngo','company','grassroots']\n",
    "\n",
    "for item, frame in df['description'].iteritems():\n",
    "    if pd.notnull(frame):\n",
    "        clean = p.clean(frame)\n",
    "        # token seperates tweets into lists of words\n",
    "        token = word_tokenize(clean)\n",
    "        if terms[0] in token or terms[1] in token or terms[2] in token or terms[3] in token:\n",
    "            bios.append(1)\n",
    "        else:\n",
    "            bios.append(0)\n",
    "    else:\n",
    "        bios.append(0)\n",
    "df['bio_pronouns'] = bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10212, 89)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the bios\n",
    "df = df[df['bio_pronouns'] != 1]\n",
    "df = df.iloc[:,:-1]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098 confirmed business, organisations or known personalities\n"
     ]
    }
   ],
   "source": [
    "# see how many we've lost - saved them as a list for later\n",
    "confirmed_org = set(df_orig.username) - set(df.username)\n",
    "print(len(confirmed_org),\"confirmed business, organisations or known personalities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column name for ratio\n",
    "df.columns = ['popularity' if x=='followers_friends_ratio' else x for x in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Base methodology to identify business/organisations and personalities within our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an initial attempt at filtering out business/organisations and internet personalities from our data once bots have been removed. The aim is to use the characteristics of verified accounts in our dataset to identifiy those with similar features. Now that we have removed a large amount of obvious and popular businesses we can use the verified accounts that remain to identify other accounts (non-verified) who share similar features.\n",
    "\n",
    " - Run a logistic regression based on identifying verified users within our dataset (99% acc)\n",
    " - Using feature elimination to identify the significant features for verified users (currently at 12).\n",
    " - Identify clusters of accounts similar to those verified, currently using euclidean distance of each row as a 12x1 vector and set as 50 nearest for every verified account.\n",
    " - Collect all accounts who are within the 50 nearest neighbours for our verified accounts.\n",
    " - Assume those without a profile URL are real users - why would a business make an account without a URL?\n",
    " - Combine with our filtered businesses to create the 'org' tag\n",
    " \n",
    "We may be able to adopt the EM-algorithm for this job - the method seems to be picking out businesses but theres still some actual users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a look at those features who differ the most for verified/non-verified\n",
    "ratios = []\n",
    "\n",
    "group = df.groupby('verified').mean()\n",
    "for column in group:\n",
    "    ratio = group[column][1]/group[column][0]\n",
    "    ratios.append(ratio)\n",
    "means = pd.DataFrame({'feature':group.columns.values,'dif':ratios})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>...</th>\n",
       "      <th>hash_PT</th>\n",
       "      <th>username_urltitle_simimlarity</th>\n",
       "      <th>username_in_urltitle</th>\n",
       "      <th>username_name_similarity</th>\n",
       "      <th>username_in_bio</th>\n",
       "      <th>lower_userid</th>\n",
       "      <th>popularity</th>\n",
       "      <th>bio_sentiment_negative</th>\n",
       "      <th>bio_sentiment_neutral</th>\n",
       "      <th>bio_sentiment_positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verified</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10175</td>\n",
       "      <td>10173</td>\n",
       "      <td>10175</td>\n",
       "      <td>6972</td>\n",
       "      <td>3056</td>\n",
       "      <td>8541</td>\n",
       "      <td>10175</td>\n",
       "      <td>10175</td>\n",
       "      <td>10175</td>\n",
       "      <td>10175</td>\n",
       "      <td>...</td>\n",
       "      <td>10154</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933</td>\n",
       "      <td>6019</td>\n",
       "      <td>6019</td>\n",
       "      <td>6019</td>\n",
       "      <td>5824</td>\n",
       "      <td>10175</td>\n",
       "      <td>10175</td>\n",
       "      <td>10175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id   name  username  location   url  description  followers  \\\n",
       "verified                                                                   \n",
       "0         10175  10173     10175      6972  3056         8541      10175   \n",
       "1            37     37        37        34    32           37         37   \n",
       "\n",
       "          friends  favourites_count  statuses_count  ...  hash_PT  \\\n",
       "verified                                             ...            \n",
       "0           10175             10175           10175  ...    10154   \n",
       "1              37                37              37  ...       37   \n",
       "\n",
       "          username_urltitle_simimlarity  username_in_urltitle  \\\n",
       "verified                                                        \n",
       "0                                  1933                  1933   \n",
       "1                                    28                    28   \n",
       "\n",
       "          username_name_similarity  username_in_bio  lower_userid  popularity  \\\n",
       "verified                                                                        \n",
       "0                             6019             6019          6019        5824   \n",
       "1                               34               34            34          34   \n",
       "\n",
       "          bio_sentiment_negative  bio_sentiment_neutral  \\\n",
       "verified                                                  \n",
       "0                          10175                  10175   \n",
       "1                             37                     37   \n",
       "\n",
       "          bio_sentiment_positive  \n",
       "verified                          \n",
       "0                          10175  \n",
       "1                             37  \n",
       "\n",
       "[2 rows x 88 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing the averages \n",
    "df.groupby('verified').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>followers</td>\n",
       "      <td>5.464861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>OGTratio</td>\n",
       "      <td>2.902630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>favourite_count</td>\n",
       "      <td>2.836583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>bio_sentiment_negative</td>\n",
       "      <td>2.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>popularity</td>\n",
       "      <td>2.011863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friends</td>\n",
       "      <td>1.999211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>followers_age</td>\n",
       "      <td>1.938630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>statuses_count</td>\n",
       "      <td>1.894163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>days_active</td>\n",
       "      <td>1.700241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>bio_sentiment_neutral</td>\n",
       "      <td>1.531086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature       dif\n",
       "1                followers  5.464861\n",
       "42                OGTratio  2.902630\n",
       "25         favourite_count  2.836583\n",
       "79  bio_sentiment_negative  2.115385\n",
       "78              popularity  2.011863\n",
       "2                  friends  1.999211\n",
       "8            followers_age  1.938630\n",
       "4           statuses_count  1.894163\n",
       "7              days_active  1.700241\n",
       "80   bio_sentiment_neutral  1.531086"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ranking\n",
    "means = means.sort_values('dif',ascending=False)\n",
    "means.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can be pretty certain that those verified are not real people (personalities, organisations etc) - we can also see how some features appear to differ drastically for verified users, even the features that are based on followings are expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10212 entries, 0 to 11339\n",
      "Data columns (total 81 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              10212 non-null  float64\n",
      " 1   verified                        10212 non-null  int64  \n",
      " 2   friends                         10212 non-null  int64  \n",
      " 3   favourites_count                10212 non-null  int64  \n",
      " 4   statuses_count                  10212 non-null  int64  \n",
      " 5   default_profile                 10212 non-null  int64  \n",
      " 6   default_profile_image           10212 non-null  int64  \n",
      " 7   days_active                     10212 non-null  int64  \n",
      " 8   following_age                   10212 non-null  float64\n",
      " 9   favourites_age                  10212 non-null  float64\n",
      " 10  tweets_age                      10212 non-null  float64\n",
      " 11  username_char_len               10212 non-null  int64  \n",
      " 12  name_ratio                      10212 non-null  float64\n",
      " 13  username_int                    10212 non-null  int64  \n",
      " 14  username_char                   10212 non-null  int64  \n",
      " 15  username_other                  10212 non-null  int64  \n",
      " 16  username_int_end                10212 non-null  int64  \n",
      " 17  name_int                        10212 non-null  int64  \n",
      " 18  non_unique_tweets               10191 non-null  float64\n",
      " 19  average_tweets_day              10191 non-null  float64\n",
      " 20  average_minutes_between_tweets  10180 non-null  float64\n",
      " 21  average_hours_tweeted           10191 non-null  float64\n",
      " 22  tweetid                         10191 non-null  float64\n",
      " 23  retweet_count                   10191 non-null  float64\n",
      " 24  favourite_count                 10191 non-null  float64\n",
      " 25  swears                          10191 non-null  float64\n",
      " 26  polite                          10191 non-null  float64\n",
      " 27  fourchan                        10191 non-null  float64\n",
      " 28  log_swears                      10191 non-null  float64\n",
      " 29  log_polite                      10191 non-null  float64\n",
      " 30  log_fourchan                    10191 non-null  float64\n",
      " 31  office_hours_utc                10191 non-null  float64\n",
      " 32  office_hours_est                10191 non-null  float64\n",
      " 33  office_hours_pct                10191 non-null  float64\n",
      " 34  office_hours_mst                10191 non-null  float64\n",
      " 35  office_hours_aus                10191 non-null  float64\n",
      " 36  tot_tweets                      10191 non-null  float64\n",
      " 37  retweets                        10191 non-null  float64\n",
      " 38  ogtweets                        10191 non-null  float64\n",
      " 39  retweet_countOT                 10191 non-null  float64\n",
      " 40  favourite_countOT               10191 non-null  float64\n",
      " 41  OGTratio                        10191 non-null  float64\n",
      " 42  char_OT                         10191 non-null  float64\n",
      " 43  ment_OT                         10191 non-null  float64\n",
      " 44  w/urlR_OT                       10191 non-null  float64\n",
      " 45  sent_OT                         10191 non-null  float64\n",
      " 46  words_OT                        10191 non-null  float64\n",
      " 47  alp_OT                          10191 non-null  float64\n",
      " 48  cap_OT                          10191 non-null  float64\n",
      " 49  capR_OT                         10191 non-null  float64\n",
      " 50  TCW_OT                          10191 non-null  float64\n",
      " 51  TSW_OT                          10191 non-null  float64\n",
      " 52  nHW_OT                          10191 non-null  float64\n",
      " 53  StopW_OT                        10191 non-null  float64\n",
      " 54  nouns_OT                        10191 non-null  float64\n",
      " 55  adj_OT                          10191 non-null  float64\n",
      " 56  verbs_OT                        10191 non-null  float64\n",
      " 57  adv_OT                          10191 non-null  float64\n",
      " 58  pron_OT                         10191 non-null  float64\n",
      " 59  Tot_entities_OT                 10191 non-null  float64\n",
      " 60  People_OT                       10191 non-null  float64\n",
      " 61  ORGs_OT                         10191 non-null  float64\n",
      " 62  pHW_OT                          10191 non-null  float64\n",
      " 63  pStopW_OT                       10191 non-null  float64\n",
      " 64  pnouns_OT                       10191 non-null  float64\n",
      " 65  padj_OT                         10191 non-null  float64\n",
      " 66  pverbs_OT                       10191 non-null  float64\n",
      " 67  padv_OT                         10191 non-null  float64\n",
      " 68  ppron_OT                        10191 non-null  float64\n",
      " 69  Gun_Index                       10191 non-null  float64\n",
      " 70  tot_hashtags                    10191 non-null  float64\n",
      " 71  hash_PT                         10191 non-null  float64\n",
      " 72  username_urltitle_simimlarity   1961 non-null   float64\n",
      " 73  username_in_urltitle            1961 non-null   float64\n",
      " 74  username_name_similarity        6053 non-null   float64\n",
      " 75  username_in_bio                 6053 non-null   float64\n",
      " 76  lower_userid                    6053 non-null   float64\n",
      " 77  popularity                      5858 non-null   float64\n",
      " 78  bio_sentiment_negative          10212 non-null  int64  \n",
      " 79  bio_sentiment_neutral           10212 non-null  int64  \n",
      " 80  bio_sentiment_positive          10212 non-null  int64  \n",
      "dtypes: float64(65), int64(16)\n",
      "memory usage: 6.4 MB\n"
     ]
    }
   ],
   "source": [
    "# start prepping for regression\n",
    "log_df = df.select_dtypes(exclude=['object'])\n",
    "log_df = log_df[log_df.columns.drop(list(log_df.filter(regex='followers')))] # followers_frien\n",
    "log_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10180 entries, 0 to 11339\n",
      "Data columns (total 73 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              10180 non-null  float64\n",
      " 1   verified                        10180 non-null  int64  \n",
      " 2   friends                         10180 non-null  int64  \n",
      " 3   favourites_count                10180 non-null  int64  \n",
      " 4   statuses_count                  10180 non-null  int64  \n",
      " 5   default_profile                 10180 non-null  int64  \n",
      " 6   default_profile_image           10180 non-null  int64  \n",
      " 7   days_active                     10180 non-null  int64  \n",
      " 8   following_age                   10180 non-null  float64\n",
      " 9   favourites_age                  10180 non-null  float64\n",
      " 10  tweets_age                      10180 non-null  float64\n",
      " 11  username_char_len               10180 non-null  int64  \n",
      " 12  name_ratio                      10180 non-null  float64\n",
      " 13  username_int                    10180 non-null  int64  \n",
      " 14  username_char                   10180 non-null  int64  \n",
      " 15  username_other                  10180 non-null  int64  \n",
      " 16  username_int_end                10180 non-null  int64  \n",
      " 17  name_int                        10180 non-null  int64  \n",
      " 18  non_unique_tweets               10180 non-null  float64\n",
      " 19  average_tweets_day              10180 non-null  float64\n",
      " 20  average_minutes_between_tweets  10180 non-null  float64\n",
      " 21  average_hours_tweeted           10180 non-null  float64\n",
      " 22  tweetid                         10180 non-null  float64\n",
      " 23  retweet_count                   10180 non-null  float64\n",
      " 24  favourite_count                 10180 non-null  float64\n",
      " 25  swears                          10180 non-null  float64\n",
      " 26  polite                          10180 non-null  float64\n",
      " 27  fourchan                        10180 non-null  float64\n",
      " 28  log_swears                      10180 non-null  float64\n",
      " 29  log_polite                      10180 non-null  float64\n",
      " 30  log_fourchan                    10180 non-null  float64\n",
      " 31  office_hours_utc                10180 non-null  float64\n",
      " 32  office_hours_est                10180 non-null  float64\n",
      " 33  office_hours_pct                10180 non-null  float64\n",
      " 34  office_hours_mst                10180 non-null  float64\n",
      " 35  office_hours_aus                10180 non-null  float64\n",
      " 36  tot_tweets                      10180 non-null  float64\n",
      " 37  retweets                        10180 non-null  float64\n",
      " 38  ogtweets                        10180 non-null  float64\n",
      " 39  retweet_countOT                 10180 non-null  float64\n",
      " 40  favourite_countOT               10180 non-null  float64\n",
      " 41  OGTratio                        10180 non-null  float64\n",
      " 42  char_OT                         10180 non-null  float64\n",
      " 43  ment_OT                         10180 non-null  float64\n",
      " 44  w/urlR_OT                       10180 non-null  float64\n",
      " 45  sent_OT                         10180 non-null  float64\n",
      " 46  words_OT                        10180 non-null  float64\n",
      " 47  alp_OT                          10180 non-null  float64\n",
      " 48  cap_OT                          10180 non-null  float64\n",
      " 49  capR_OT                         10180 non-null  float64\n",
      " 50  TCW_OT                          10180 non-null  float64\n",
      " 51  TSW_OT                          10180 non-null  float64\n",
      " 52  nHW_OT                          10180 non-null  float64\n",
      " 53  StopW_OT                        10180 non-null  float64\n",
      " 54  nouns_OT                        10180 non-null  float64\n",
      " 55  adj_OT                          10180 non-null  float64\n",
      " 56  verbs_OT                        10180 non-null  float64\n",
      " 57  adv_OT                          10180 non-null  float64\n",
      " 58  pron_OT                         10180 non-null  float64\n",
      " 59  Tot_entities_OT                 10180 non-null  float64\n",
      " 60  People_OT                       10180 non-null  float64\n",
      " 61  ORGs_OT                         10180 non-null  float64\n",
      " 62  pHW_OT                          10180 non-null  float64\n",
      " 63  pStopW_OT                       10180 non-null  float64\n",
      " 64  pnouns_OT                       10180 non-null  float64\n",
      " 65  padj_OT                         10180 non-null  float64\n",
      " 66  pverbs_OT                       10180 non-null  float64\n",
      " 67  padv_OT                         10180 non-null  float64\n",
      " 68  ppron_OT                        10180 non-null  float64\n",
      " 69  Gun_Index                       10180 non-null  float64\n",
      " 70  tot_hashtags                    10180 non-null  float64\n",
      " 71  hash_PT                         10180 non-null  float64\n",
      " 72  bio_sentiment_positive          10180 non-null  int64  \n",
      "dtypes: float64(59), int64(14)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "# incomplete so we dont need these\n",
    "log_df = log_df.drop(columns=['username_in_urltitle','username_urltitle_simimlarity'])\n",
    "log_df = log_df.drop([log_df.columns[72],log_df.columns[73],log_df.columns[74],log_df.columns[75],log_df.columns[76],log_df.columns[77]],axis='columns')\n",
    "log_df = log_df.dropna()\n",
    "log_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10180"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model data\n",
    "ids = log_df.id.copy()\n",
    "sum(ids.notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Normalise the data for logisitic regression (y = verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified</th>\n",
       "      <th>friends</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>days_active</th>\n",
       "      <th>following_age</th>\n",
       "      <th>favourites_age</th>\n",
       "      <th>tweets_age</th>\n",
       "      <th>...</th>\n",
       "      <th>pStopW_OT</th>\n",
       "      <th>pnouns_OT</th>\n",
       "      <th>padj_OT</th>\n",
       "      <th>pverbs_OT</th>\n",
       "      <th>padv_OT</th>\n",
       "      <th>ppron_OT</th>\n",
       "      <th>Gun_Index</th>\n",
       "      <th>tot_hashtags</th>\n",
       "      <th>hash_PT</th>\n",
       "      <th>bio_sentiment_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>0.021961</td>\n",
       "      <td>0.015647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615776</td>\n",
       "      <td>0.245029</td>\n",
       "      <td>0.096613</td>\n",
       "      <td>0.407318</td>\n",
       "      <td>0.216510</td>\n",
       "      <td>0.270300</td>\n",
       "      <td>0.153624</td>\n",
       "      <td>0.017363</td>\n",
       "      <td>0.017450</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647394</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667429</td>\n",
       "      <td>0.267583</td>\n",
       "      <td>0.109357</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.208967</td>\n",
       "      <td>0.216864</td>\n",
       "      <td>0.202547</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037723</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145358</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.025214</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727797</td>\n",
       "      <td>0.267506</td>\n",
       "      <td>0.109827</td>\n",
       "      <td>0.512139</td>\n",
       "      <td>0.295954</td>\n",
       "      <td>0.279410</td>\n",
       "      <td>0.151716</td>\n",
       "      <td>0.020659</td>\n",
       "      <td>0.020659</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026016</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571661</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659917</td>\n",
       "      <td>0.295754</td>\n",
       "      <td>0.109989</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.324479</td>\n",
       "      <td>0.137338</td>\n",
       "      <td>0.222640</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184811</td>\n",
       "      <td>0.094952</td>\n",
       "      <td>0.048698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.751425</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.024047</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464603</td>\n",
       "      <td>0.192439</td>\n",
       "      <td>0.073210</td>\n",
       "      <td>0.353316</td>\n",
       "      <td>0.129443</td>\n",
       "      <td>0.207008</td>\n",
       "      <td>0.191665</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055433</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154112</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628288</td>\n",
       "      <td>0.223986</td>\n",
       "      <td>0.072854</td>\n",
       "      <td>0.596806</td>\n",
       "      <td>0.306055</td>\n",
       "      <td>0.406923</td>\n",
       "      <td>0.125263</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481270</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774202</td>\n",
       "      <td>0.279799</td>\n",
       "      <td>0.114917</td>\n",
       "      <td>0.465748</td>\n",
       "      <td>0.249696</td>\n",
       "      <td>0.237818</td>\n",
       "      <td>0.131125</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10177</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161645</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750188</td>\n",
       "      <td>0.258407</td>\n",
       "      <td>0.119785</td>\n",
       "      <td>0.445158</td>\n",
       "      <td>0.227298</td>\n",
       "      <td>0.190173</td>\n",
       "      <td>0.228315</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10178</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.022056</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068607</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.059732</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745565</td>\n",
       "      <td>0.279788</td>\n",
       "      <td>0.107020</td>\n",
       "      <td>0.494468</td>\n",
       "      <td>0.337276</td>\n",
       "      <td>0.286141</td>\n",
       "      <td>0.146541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10179</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075745</td>\n",
       "      <td>0.020535</td>\n",
       "      <td>0.036592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700733</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695507</td>\n",
       "      <td>0.244618</td>\n",
       "      <td>0.084211</td>\n",
       "      <td>0.424060</td>\n",
       "      <td>0.306767</td>\n",
       "      <td>0.291310</td>\n",
       "      <td>0.147540</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10180 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       verified   friends  favourites_count  statuses_count  default_profile  \\\n",
       "0           0.0  0.020913          0.001523        0.000725              1.0   \n",
       "1           0.0  0.000400          0.000778        0.000214              1.0   \n",
       "2           0.0  0.037723          0.019455        0.001589              1.0   \n",
       "3           0.0  0.026016          0.010790        0.001578              0.0   \n",
       "4           0.0  0.184811          0.094952        0.048698              0.0   \n",
       "...         ...       ...               ...             ...              ...   \n",
       "10175       0.0  0.055433          0.005258        0.002633              1.0   \n",
       "10176       0.0  0.051531          0.000966        0.000507              0.0   \n",
       "10177       0.0  0.003202          0.005174        0.002321              1.0   \n",
       "10178       0.0  0.017911          0.022056        0.001415              1.0   \n",
       "10179       0.0  0.075745          0.020535        0.036592              0.0   \n",
       "\n",
       "       default_profile_image  days_active  following_age  favourites_age  \\\n",
       "0                        0.0     0.011401       0.023114        0.021961   \n",
       "1                        0.0     0.647394       0.000009        0.000229   \n",
       "2                        0.0     0.145358       0.003748        0.025214   \n",
       "3                        0.0     0.571661       0.000663        0.003589   \n",
       "4                        0.0     0.751425       0.003588        0.024047   \n",
       "...                      ...          ...            ...             ...   \n",
       "10175                    0.0     0.154112       0.005199        0.006432   \n",
       "10176                    0.0     0.481270       0.001560        0.000382   \n",
       "10177                    0.0     0.161645       0.000286        0.006038   \n",
       "10178                    0.0     0.068607       0.003719        0.059732   \n",
       "10179                    0.0     0.700733       0.001577        0.005576   \n",
       "\n",
       "       tweets_age  ...  pStopW_OT  pnouns_OT   padj_OT  pverbs_OT   padv_OT  \\\n",
       "0        0.015647  ...   0.615776   0.245029  0.096613   0.407318  0.216510   \n",
       "1        0.000094  ...   0.667429   0.267583  0.109357   0.426901  0.208967   \n",
       "2        0.003080  ...   0.727797   0.267506  0.109827   0.512139  0.295954   \n",
       "3        0.000785  ...   0.659917   0.295754  0.109989   0.404167  0.324479   \n",
       "4        0.018435  ...   0.464603   0.192439  0.073210   0.353316  0.129443   \n",
       "...           ...  ...        ...        ...       ...        ...       ...   \n",
       "10175    0.004816  ...   0.628288   0.223986  0.072854   0.596806  0.306055   \n",
       "10176    0.000299  ...   0.774202   0.279799  0.114917   0.465748  0.249696   \n",
       "10177    0.004050  ...   0.750188   0.258407  0.119785   0.445158  0.227298   \n",
       "10178    0.005732  ...   0.745565   0.279788  0.107020   0.494468  0.337276   \n",
       "10179    0.014851  ...   0.695507   0.244618  0.084211   0.424060  0.306767   \n",
       "\n",
       "       ppron_OT  Gun_Index  tot_hashtags   hash_PT  bio_sentiment_positive  \n",
       "0      0.270300   0.153624      0.017363  0.017450                     0.0  \n",
       "1      0.216864   0.202547      0.015385  0.015385                     0.0  \n",
       "2      0.279410   0.151716      0.020659  0.020659                     0.0  \n",
       "3      0.137338   0.222640      0.000220  0.000220                     1.0  \n",
       "4      0.207008   0.191665      0.001978  0.001988                     1.0  \n",
       "...         ...        ...           ...       ...                     ...  \n",
       "10175  0.406923   0.125263      0.001978  0.001978                     0.0  \n",
       "10176  0.237818   0.131125      0.000659  0.000659                     0.0  \n",
       "10177  0.190173   0.228315      0.000879  0.000879                     0.0  \n",
       "10178  0.286141   0.146541      0.000000  0.000000                     0.0  \n",
       "10179  0.291310   0.147540      0.001099  0.001099                     1.0  \n",
       "\n",
       "[10180 rows x 72 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# many features so we'll normalise to assist convergence\n",
    "log_df = log_df.iloc[:,1:]\n",
    "x = log_df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "scaled_X= pd.DataFrame(x_scaled,columns=log_df.columns)\n",
    "scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test\n",
    "X = scaled_X.iloc[:,1:]\n",
    "y = scaled_X.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model (upped the iterations because f is high)\n",
    "logreg= LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friends - 1.0571103094944976\n",
      "favourites_count - -0.04398674140117255\n",
      "statuses_count - 0.15106954523812036\n",
      "default_profile - -0.6051120137305005\n",
      "default_profile_image - -0.4169524369087506\n",
      "days_active - 1.9476592425283885\n",
      "following_age - -0.03924361772137932\n",
      "favourites_age - -0.16637931305708994\n",
      "tweets_age - 0.002566416929938712\n",
      "username_char_len - 0.1785509562926145\n",
      "name_ratio - -0.14287330054634154\n",
      "username_int - -0.7213108546687254\n",
      "username_char - 0.7670196331893508\n",
      "username_other - -0.13899689985915267\n",
      "username_int_end - -0.6462438040693672\n",
      "name_int - -0.22720820621048057\n",
      "non_unique_tweets - -0.17782870607487813\n",
      "average_tweets_day - -0.5915371297904635\n",
      "average_minutes_between_tweets - -0.014448475718815275\n",
      "average_hours_tweeted - 0.8523736799841825\n",
      "tweetid - 0.20778510266127848\n",
      "retweet_count - -0.14509418018405762\n",
      "favourite_count - 0.1338698004214858\n",
      "swears - -0.31177423507046315\n",
      "polite - 0.257032871192424\n",
      "fourchan - 0.013586933934602507\n",
      "log_swears - -0.8345105459568997\n",
      "log_polite - 0.6985756378331154\n",
      "log_fourchan - 0.41295898559144456\n",
      "office_hours_utc - -0.004844382473842718\n",
      "office_hours_est - -0.5054560717123204\n",
      "office_hours_pct - -0.29660206782389537\n",
      "office_hours_mst - -0.4602677248505803\n",
      "office_hours_aus - 0.4511993390914864\n",
      "tot_tweets - 0.42132047741371614\n",
      "retweets - 0.055822658683613836\n",
      "ogtweets - 0.361278316785706\n",
      "retweet_countOT - 0.02319387690641443\n",
      "favourite_countOT - -0.0020097437781244204\n",
      "OGTratio - 0.17720575900141713\n",
      "char_OT - -0.13618684491768976\n",
      "ment_OT - -0.22742331683941375\n",
      "w/urlR_OT - 0.7420109509798858\n",
      "sent_OT - -0.15988412328870832\n",
      "words_OT - 0.31230900726758476\n",
      "alp_OT - 0.3485219580983205\n",
      "cap_OT - -0.18916794977704934\n",
      "capR_OT - -0.38550925650317713\n",
      "TCW_OT - 0.291647512267452\n",
      "TSW_OT - 0.33343710438692575\n",
      "nHW_OT - 0.19063902929275156\n",
      "StopW_OT - 0.6195292166418691\n",
      "nouns_OT - 0.6513998034932711\n",
      "adj_OT - 0.5987580320284279\n",
      "verbs_OT - 0.2111448687520836\n",
      "adv_OT - 0.30648362428371667\n",
      "pron_OT - -0.4396493416679194\n",
      "Tot_entities_OT - 0.07245822106345708\n",
      "People_OT - -0.10883731637185227\n",
      "ORGs_OT - -0.06477778358920862\n",
      "pHW_OT - -0.13663414829898884\n",
      "pStopW_OT - 1.242576260722482\n",
      "pnouns_OT - 0.47565408610588433\n",
      "padj_OT - 0.23581519954240923\n",
      "pverbs_OT - 0.026396280168906265\n",
      "padv_OT - 0.2935464717554595\n",
      "ppron_OT - -0.26613832480910077\n",
      "Gun_Index - 0.032010068397126175\n",
      "tot_hashtags - -0.24457085378269508\n",
      "hash_PT - -0.25323698785638604\n",
      "\n",
      "LogisticRegression accuracy is 0.996\n"
     ]
    }
   ],
   "source": [
    "# coefficient ranking would be a place to start\n",
    "coefs = []\n",
    "\n",
    "for i in list(range(0,len(X.columns)-1)):\n",
    "    print(X.columns[i],\"-\",logreg.coef_[0,i])\n",
    "    coefs.append(logreg.coef_[0,i])\n",
    "    \n",
    "print(\"\") \n",
    "\n",
    "# CV accuracy (10)\n",
    "y_pred = cross_val_predict(logreg,X,y,cv=10)\n",
    "print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y, y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>days_active</td>\n",
       "      <td>1.947659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>pStopW_OT</td>\n",
       "      <td>1.242576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>friends</td>\n",
       "      <td>1.057110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>average_hours_tweeted</td>\n",
       "      <td>0.852374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>username_char</td>\n",
       "      <td>0.767020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>average_tweets_day</td>\n",
       "      <td>-0.591537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>default_profile</td>\n",
       "      <td>-0.605112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>username_int_end</td>\n",
       "      <td>-0.646244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>username_int</td>\n",
       "      <td>-0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>log_swears</td>\n",
       "      <td>-0.834511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature      coef\n",
       "5             days_active  1.947659\n",
       "61              pStopW_OT  1.242576\n",
       "0                 friends  1.057110\n",
       "19  average_hours_tweeted  0.852374\n",
       "12          username_char  0.767020\n",
       "..                    ...       ...\n",
       "17     average_tweets_day -0.591537\n",
       "3         default_profile -0.605112\n",
       "14       username_int_end -0.646244\n",
       "11           username_int -0.721311\n",
       "26             log_swears -0.834511\n",
       "\n",
       "[70 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'feature':X.columns[:-1],'coef':coefs})\n",
    "results.sort_values('coef',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Recursive feature elimination to find our optimal coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup RFE\n",
    "\n",
    "estimator = logreg\n",
    "selector = RFE(estimator, 12, step=1)\n",
    "selector = selector.fit(X, y)\n",
    "rfe_list = list(selector.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with our optimal features\n",
    "X = X.loc[:,rfe_list]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg= LogisticRegression()\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friends - 1.1447573292214348\n",
      "days_active - 2.364292034102041\n",
      "username_int - -0.9273591319382776\n",
      "username_char - 0.9699208620052506\n",
      "log_swears - -0.829537915075584\n",
      "log_polite - 0.7266491663336396\n",
      "office_hours_aus - 0.7552141588288608\n",
      "w/urlR_OT - 0.8163098625894485\n",
      "StopW_OT - 1.0794962729361273\n",
      "nouns_OT - 0.9492231918152106\n",
      "adj_OT - 0.9088317060572126\n",
      "pStopW_OT - 1.3261330080934364\n",
      "\n",
      "LogisticRegression accuracy is 0.996\n"
     ]
    }
   ],
   "source": [
    "coefs = []\n",
    "\n",
    "for i in list(range(0,len(X.columns))):\n",
    "    print(X.columns[i],\"-\",logreg.coef_[0,i])\n",
    "    coefs.append(logreg.coef_[0,i])\n",
    "    \n",
    "print(\"\") \n",
    "y_pred = cross_val_predict(logreg,X,y,cv=10)\n",
    "print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y, y_pred))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Cluster the data by distance to verified users as represented as a vector (12x1) for each account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of our model doesn't matter too much. Considering the small amount of positives (verified) it won't be that difficult for a regression model to identify negatives. But we can use these key features for our searching algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>friends</th>\n",
       "      <th>days_active</th>\n",
       "      <th>username_int</th>\n",
       "      <th>username_char</th>\n",
       "      <th>log_swears</th>\n",
       "      <th>log_polite</th>\n",
       "      <th>office_hours_aus</th>\n",
       "      <th>w/urlR_OT</th>\n",
       "      <th>StopW_OT</th>\n",
       "      <th>nouns_OT</th>\n",
       "      <th>adj_OT</th>\n",
       "      <th>pStopW_OT</th>\n",
       "      <th>verified</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.499040</td>\n",
       "      <td>0.339121</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.179369</td>\n",
       "      <td>0.166323</td>\n",
       "      <td>0.615776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.230000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.647394</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.228514</td>\n",
       "      <td>0.141187</td>\n",
       "      <td>0.135696</td>\n",
       "      <td>0.667429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.489127e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037723</td>\n",
       "      <td>0.145358</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.498093</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.403061</td>\n",
       "      <td>0.254670</td>\n",
       "      <td>0.144254</td>\n",
       "      <td>0.139280</td>\n",
       "      <td>0.727797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.930000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026016</td>\n",
       "      <td>0.571661</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.452261</td>\n",
       "      <td>0.551018</td>\n",
       "      <td>0.380570</td>\n",
       "      <td>0.332842</td>\n",
       "      <td>0.659917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.515698e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.184811</td>\n",
       "      <td>0.751425</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.435534</td>\n",
       "      <td>0.304710</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.186663</td>\n",
       "      <td>0.119150</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.464603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.222358e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10175</th>\n",
       "      <td>0.055433</td>\n",
       "      <td>0.154112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303764</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.141805</td>\n",
       "      <td>0.077908</td>\n",
       "      <td>0.059594</td>\n",
       "      <td>0.628288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.780000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.481270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.367269</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.361809</td>\n",
       "      <td>0.253662</td>\n",
       "      <td>0.141278</td>\n",
       "      <td>0.136458</td>\n",
       "      <td>0.774202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.161878e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10177</th>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.161645</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.338175</td>\n",
       "      <td>0.434588</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533113</td>\n",
       "      <td>0.282997</td>\n",
       "      <td>0.308507</td>\n",
       "      <td>0.750188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.640000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10178</th>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.068607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.763082</td>\n",
       "      <td>0.414702</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>0.277668</td>\n",
       "      <td>0.160582</td>\n",
       "      <td>0.144451</td>\n",
       "      <td>0.745565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.130000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10179</th>\n",
       "      <td>0.075745</td>\n",
       "      <td>0.700733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.260082</td>\n",
       "      <td>0.140970</td>\n",
       "      <td>0.114127</td>\n",
       "      <td>0.695507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.163533e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10180 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        friends  days_active  username_int  username_char  log_swears  \\\n",
       "0      0.020913     0.011401      0.272727       0.400000    0.499040   \n",
       "1      0.000400     0.647394      0.272727       0.200000    0.392472   \n",
       "2      0.037723     0.145358      0.181818       0.400000    0.498093   \n",
       "3      0.026016     0.571661      0.181818       0.400000    0.303764   \n",
       "4      0.184811     0.751425      0.181818       0.266667    0.435534   \n",
       "...         ...          ...           ...            ...         ...   \n",
       "10175  0.055433     0.154112      0.000000       0.400000    1.000000   \n",
       "10176  0.051531     0.481270      0.000000       0.866667    0.434588   \n",
       "10177  0.003202     0.161645      0.090909       0.400000    0.338175   \n",
       "10178  0.017911     0.068607      0.000000       0.533333    0.763082   \n",
       "10179  0.075745     0.700733      0.000000       1.000000    0.452577   \n",
       "\n",
       "       log_polite  office_hours_aus  w/urlR_OT  StopW_OT  nouns_OT    adj_OT  \\\n",
       "0        0.339121             0.392   0.358696  0.292500  0.179369  0.166323   \n",
       "1        0.511115             0.310   0.257576  0.228514  0.141187  0.135696   \n",
       "2        0.303764             0.570   0.403061  0.254670  0.144254  0.139280   \n",
       "3        0.434588             0.405   0.452261  0.551018  0.380570  0.332842   \n",
       "4        0.304710             0.377   0.129032  0.186663  0.119150  0.106600   \n",
       "...           ...               ...        ...       ...       ...       ...   \n",
       "10175    0.303764             0.455   0.187500  0.141805  0.077908  0.059594   \n",
       "10176    0.367269             0.415   0.361809  0.253662  0.141278  0.136458   \n",
       "10177    0.434588             0.165   0.000000  0.533113  0.282997  0.308507   \n",
       "10178    0.414702             0.655   0.215054  0.277668  0.160582  0.144451   \n",
       "10179    0.452577             0.560   0.574468  0.260082  0.140970  0.114127   \n",
       "\n",
       "       pStopW_OT  verified           ids  \n",
       "0       0.615776       0.0  1.230000e+18  \n",
       "1       0.667429       0.0  3.489127e+08  \n",
       "2       0.727797       0.0  9.930000e+17  \n",
       "3       0.659917       0.0  7.515698e+08  \n",
       "4       0.464603       0.0  1.222358e+08  \n",
       "...          ...       ...           ...  \n",
       "10175   0.628288       0.0  9.780000e+17  \n",
       "10176   0.774202       0.0  2.161878e+09  \n",
       "10177   0.750188       0.0  9.640000e+17  \n",
       "10178   0.745565       0.0  1.130000e+18  \n",
       "10179   0.695507       0.0  2.163533e+08  \n",
       "\n",
       "[10180 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just add in the truths and ids for joining\n",
    "X['verified'] = y\n",
    "X['ids'] = list(ids)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# we will use nearest neighbours to find those accounts with similar features to our verified \n",
    "X_verified = X.loc[X['verified']==1]\n",
    "X_not_verified = X.loc[X['verified']==0]\n",
    "X_verified = X_verified.iloc[:,:-2]\n",
    "print(len(X_verified))\n",
    "X_not_verified = X_not_verified.iloc[:,:-2]\n",
    "\n",
    "# brute force just means it will literally take the distance between all pairs which is fine for our sample size\n",
    "nbrs = NearestNeighbors(n_neighbors=50, algorithm='brute').fit(X_not_verified)\n",
    "distances, indices = nbrs.kneighbors(X_verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037 suspected business/orgs!\n"
     ]
    }
   ],
   "source": [
    "# see what accounts are suspect\n",
    "test = np.concatenate(indices,axis=0)\n",
    "link = X.iloc[test,-1]\n",
    "print(len(set(link)),\"suspected business/orgs!\")\n",
    "\n",
    "test_df = df[df['id'].isin(link)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4487, 90)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# account info for visual inspection \n",
    "pivot = pd.DataFrame({'ids':link,'count':1})\n",
    "grouper = pivot.groupby('ids').sum()\n",
    "grouper.sort_values('count')\n",
    "test_df = test_df.merge(grouper,left_on='id',right_on=grouper.index)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add variable to df\n",
    "suspected = []\n",
    "for i in df.id:\n",
    "    if i in set(link):\n",
    "        suspected.append(1)\n",
    "    else:\n",
    "        suspected.append(0)\n",
    "df['suspected_business'] = suspected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have x amount of suspected accounts - we are now making the assumption that those accounts who **don't** have a bio URL are not a business/organisation or NGO. This is more based on the idea that why would corporate social media accounts not contain a link to a site or other social media? Even @Twitter has a link..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1041, 90)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets drop those without and store as suspected_org\n",
    "df_dropped = df.loc[(df.url.notnull() == True) & (df.suspected_business == 1)]\n",
    "df_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspected_org = set(df_dropped.username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 90)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_verified = df[df['verified']==1]\n",
    "df_verified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_org = set(df_verified.username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out whats left (our humans!)\n",
    "df_new = df.drop(df[(df['url'].notnull()==True) & (df['suspected_business'] == 1)].index)\n",
    "df_new = df_new[df_new['verified']==0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.verified.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to check everything has gone through\n",
    "humans = set(df_new.username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098\n",
      "1041\n",
      "37\n",
      "9139\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(confirmed_org))\n",
    "print(len(suspected_org))\n",
    "print(len(verified_org))\n",
    "print(len(humans))\n",
    "print(len(bots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11315\n",
      "11310\n"
     ]
    }
   ],
   "source": [
    "hits = list(confirmed_org) + list(suspected_org) + list(humans) + list(verified_org)\n",
    "print(len(hits))\n",
    "print(len(set(df_orig.username)))\n",
    "\n",
    "# five unnaccounted for!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs = pd.DataFrame({'username':list(confirmed_org),'tag':'org'})\n",
    "orgs_sus = pd.DataFrame({'username':list(suspected_org),'tag':'org'})\n",
    "orgs_verified = pd.DataFrame({'username':list(verified_org),'tag':'org'})\n",
    "humans_ = pd.DataFrame({'username':list(humans),'tag':'human'})\n",
    "bots = pd.DataFrame({'username':list(bots),'tag':'bot'})\n",
    "\n",
    "final_df = pd.concat([orgs,orgs_sus,orgs_verified,humans_,bots],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bot</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>9139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>2176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       username\n",
       "tag            \n",
       "bot          24\n",
       "human      9139\n",
       "org        2176"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.groupby('tag').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>...</th>\n",
       "      <th>username_in_urltitle</th>\n",
       "      <th>username_name_similarity</th>\n",
       "      <th>username_in_bio</th>\n",
       "      <th>lower_userid</th>\n",
       "      <th>followers_friends_ratio</th>\n",
       "      <th>bio_sentiment_negative</th>\n",
       "      <th>bio_sentiment_neutral</th>\n",
       "      <th>bio_sentiment_positive</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.230000e+18</td>\n",
       "      <td>jaleel appleseed 007</td>\n",
       "      <td>007Jaleel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/4zFqDPbEKL</td>\n",
       "      <td>Ginger Golem Goulish Goyish Soulful Murdering ...</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>209</td>\n",
       "      <td>711</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.489127e+08</td>\n",
       "      <td>BAK</td>\n",
       "      <td>009BAK</td>\n",
       "      <td>Chiang Mai, Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I am here to take what you say and feeded back...</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>363</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.930000e+17</td>\n",
       "      <td>00TurboK aka Juan Wick</td>\n",
       "      <td>00TurboK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pokemon GO player 🔥Valor🔥 First of his name, B...</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>377</td>\n",
       "      <td>9080</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.515698e+08</td>\n",
       "      <td>ravi patel</td>\n",
       "      <td>00akshar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as allways-perfect in this world n in every......</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>260</td>\n",
       "      <td>5036</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.697876e+09</td>\n",
       "      <td>F’n Idiots Everywhere</td>\n",
       "      <td>0NoMyProfile</td>\n",
       "      <td>Everywhere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World is doomed if we have to rely on the rest...</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>458</td>\n",
       "      <td>1111</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098253</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                    name      username              location  \\\n",
       "0  1.230000e+18    jaleel appleseed 007     007Jaleel                   NaN   \n",
       "1  3.489127e+08                     BAK        009BAK  Chiang Mai, Thailand   \n",
       "2  9.930000e+17  00TurboK aka Juan Wick      00TurboK                   NaN   \n",
       "3  7.515698e+08              ravi patel      00akshar                   NaN   \n",
       "4  4.697876e+09   F’n Idiots Everywhere  0NoMyProfile            Everywhere   \n",
       "\n",
       "                       url                                        description  \\\n",
       "0  https://t.co/4zFqDPbEKL  Ginger Golem Goulish Goyish Soulful Murdering ...   \n",
       "1                      NaN  I am here to take what you say and feeded back...   \n",
       "2                      NaN  Pokemon GO player 🔥Valor🔥 First of his name, B...   \n",
       "3                      NaN  as allways-perfect in this world n in every......   \n",
       "4                      NaN  World is doomed if we have to rely on the rest...   \n",
       "\n",
       "   verified  followers  friends  favourites_count  ...  username_in_urltitle  \\\n",
       "0         0         82      209               711  ...                   NaN   \n",
       "1         0        116        4               363  ...                   NaN   \n",
       "2         0        138      377              9080  ...                   NaN   \n",
       "3         0         28      260              5036  ...                   NaN   \n",
       "4         0         45      458              1111  ...                   NaN   \n",
       "\n",
       "   username_name_similarity  username_in_bio lower_userid  \\\n",
       "0                       NaN              NaN          NaN   \n",
       "1                  0.666667              0.0          1.0   \n",
       "2                       NaN              NaN          NaN   \n",
       "3                  0.222222              0.0          1.0   \n",
       "4                  0.303030              0.0          0.0   \n",
       "\n",
       "   followers_friends_ratio  bio_sentiment_negative  bio_sentiment_neutral  \\\n",
       "0                      NaN                       0                      0   \n",
       "1                29.000000                       0                      1   \n",
       "2                      NaN                       0                      0   \n",
       "3                 0.107692                       0                      0   \n",
       "4                 0.098253                       1                      0   \n",
       "\n",
       "   bio_sentiment_positive  predicted_class    tag  \n",
       "0                       0            human    org  \n",
       "1                       0            human  human  \n",
       "2                       0            human  human  \n",
       "3                       1            human  human  \n",
       "4                       0            human    org  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = df_final.merge(final_df,left_on='username',right_on='username')\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.to_csv(\"Final datasets/org_tagged_data/5G_tagged.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
